#!/bin/bash -l
#SBATCH --job-name=llmTest_job1
#SBATCH --account=nnxxxx
#SBATCH --output=output_test.log
#SBATCH --error=error_test.log
#SBATCH --time=0:30:00
#SBATCH --partition=accel
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10G
#SBATCH --gpus=1

## Set up job environment:
set -o errexit  # Exit the script on any error
set -o nounset  # Treat any unset variables as an error
module --quiet purge  # Reset the modules to the system default
module list  # List loaded modules for debugging

# Directory where the program is located
cd /cluster/work/users/your_user_name/llmTestDocker

# Start GPU monitoring in the background
nvidia-smi --query-gpu=timestamp,utilization.gpu,utilization.memory --format=csv -l 1 > gpu_usage.csv &
GPU_MONITOR_PID=$!

# Path to the Singularity image file
SINGULARITY_IMAGE=/cluster/work/users/your_user_name/llmTestDocker/llm-test.tar_latest.sif

# Run the script using Singularity with the necessary bind paths
singularity exec --nv $SINGULARITY_IMAGE python /app/main.py

# Stop GPU monitoring
kill $GPU_MONITOR_PID